{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3362f3",
   "metadata": {},
   "source": [
    "# Routing algorithm\n",
    "\n",
    "This notebook solves a vehicle routing / scheduling problem with **time-dependent travel times**.\n",
    "\n",
    "It is organized as:\n",
    "1. **Setup & parameters**\n",
    "2. **Data loading**\n",
    "3. **Distance / travel-time matrices** (shortest paths on a graph)\n",
    "4. **MILP model** (DOcplex)\n",
    "5. **Post-processing & plots**\n",
    "\n",
    "> Tip: Keep the input data in `data/` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb436cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility knobs\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from docplex.mp.model import Model\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "# Project paths\n",
    "ROOT = Path('.')\n",
    "DATA_DIR = ROOT / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d47196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User inputs: ---\n",
    "# List of coordinates (\"lat,lng\") including depot as the first element\n",
    "coords_list = [\n",
    "    \"60.,24.\",  # Depot\n",
    "    \"60.,24.\",  # BS1\n",
    "    \"60.,24.\",  # BS2\n",
    "    \"60.,24.\",  # BS3\n",
    "    \"60.,24.\",  # BS4\n",
    "    \"60.,24.\",  # BS5\n",
    "    \"60.,24.\",  # BS6\n",
    "    \"60.,24.\",  # BS7\n",
    "    \"60.,24.\",  # BS8\n",
    "    \"60.,24.\",  # BS9\n",
    "    \"60.,24.\",  # BS10\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e9728",
   "metadata": {},
   "source": [
    "## Step 1. Data Input and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23de309",
   "metadata": {},
   "outputs": [],
   "source": [
    "depo_index = 0              # index of the depot in coords_list\n",
    "\n",
    "# Define vehicle operating cost (Euros per km) and value of time (Euros per hour).\n",
    "C_o = 2.5502  # Euros per km for truck 1.2751\n",
    "C_T = 28.7   # Euros per hour 14.35\n",
    "\n",
    "# Define additional parameters.\n",
    "Truck_capacity = 6         # Vehicle capacity in packages\n",
    "Cus_demand = 1             # Demand per customer (in packages)\n",
    "MAX_TRAVEL_DISTANCE = 100  # Maximum allowed travel distance in kilometers\n",
    "service_time = 25/60         # Service time at each customer in hour\n",
    "\n",
    "# For cumulative time constraints, set a large upper bound.\n",
    "B_bar = 3            # Maximum allowed cumulative travel time (hour)\n",
    "D_bar = MAX_TRAVEL_DISTANCE  # Maximum allowed cumulative travel distance (meters)\n",
    "# Big-M \n",
    "M_big = B_bar + 10  # something larger than any possible total route time\n",
    "\n",
    "interval = 1.0    # 1 hour\n",
    "H = 2*B_bar       # 2 + of time\n",
    "\n",
    "# pick your start‐hour anywhere in 0…23\n",
    "start_hour = 13\n",
    "\n",
    "EV_cost = 50\n",
    "MC_mean = 0.6\n",
    "MC_std = 0.1\n",
    "MC = 10000\n",
    " \n",
    "# lb_factor = 1          # R  # This should be 1 if MILP_filename is \"mean\"\n",
    "\n",
    "MILP_filename = \"lb_2024-11-20.csv\"       # Mean_Out\n",
    "True_filename = \"True_2024-11-20.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e503e",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files\n",
    "df_MILP = pd.read_csv(DATA_DIR / \"Mean_Out_2024-11-20.csv\")\n",
    "df_true = pd.read_csv(DATA_DIR / \"True_2024-11-20.csv\")\n",
    "\n",
    "# df_MILP.loc[:, df_MILP.columns != \"Hours\"] *= lb_factor\n",
    "\n",
    "# Reshape both datasets into long format\n",
    "df_MILP_melted = df_MILP.melt(id_vars=\"Hours\", var_name=\"ID\", value_name=\"Mean\")\n",
    "df_true_melted = df_true.melt(id_vars=\"Hours\", var_name=\"ID\", value_name=\"True\")\n",
    "\n",
    "# Merge on Hours and ID\n",
    "df_merged = pd.merge(df_MILP_melted, df_true_melted, on=[\"Hours\", \"ID\"])\n",
    "\n",
    "# Convert ID to string for better legend readability\n",
    "df_merged[\"ID\"] = df_merged[\"ID\"].astype(str)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "ids = df_merged[\"ID\"].unique()\n",
    "colors = plt.cm.tab20.colors\n",
    "\n",
    "for i, id_val in enumerate(ids):\n",
    "    subset = df_merged[df_merged[\"ID\"] == id_val]\n",
    "    color = colors[i % len(colors)]\n",
    "    plt.plot(subset[\"Hours\"], subset[\"True\"], linestyle=\"-\", marker=\"o\", markersize=3,\n",
    "             color=color, label=f\"True {id_val}\")\n",
    "    plt.plot(subset[\"Hours\"], subset[\"Mean\"], linestyle=\"--\", marker=\"o\", markersize=3,\n",
    "             color=color, label=f\"Mean {id_val}\")\n",
    "\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Mean vs True Speeds per ID with markers\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=\"small\", ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e96c90",
   "metadata": {},
   "source": [
    "## Step 2. Build Distance and Travel Time Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Google Maps client\n",
    "\n",
    "load_dotenv()\n",
    "gmaps = googlemaps.Client(key=os.getenv(\"GOOGLE_MAPS_API_KEY\"))\n",
    "\n",
    "# # Number of locations\n",
    "# epoch_count = len(coords_list)\n",
    "\n",
    "# # Preallocate matrices\n",
    "# distance_matrix = np.zeros((epoch_count, epoch_count), dtype=float)\n",
    "# travel_time_matrix = np.zeros((epoch_count, epoch_count), dtype=float)\n",
    "\n",
    "# # Build directed graph\n",
    "# G = nx.DiGraph()\n",
    "# for idx, coord in enumerate(coords_list):\n",
    "#     G.add_node(idx, coord=coord)\n",
    "    \n",
    "    \n",
    "# # Batch API calls: one request per origin, querying all destinations\n",
    "# def fetch_matrix():\n",
    "#     for i, origin in enumerate(coords_list):\n",
    "#         result = gmaps.distance_matrix(\n",
    "#             origins=[origin],\n",
    "#             destinations=coords_list,\n",
    "#             mode='driving',\n",
    "#             departure_time=datetime.now()\n",
    "#         )\n",
    "#         elements = result['rows'][0]['elements']\n",
    "#         for j, elem in enumerate(elements):\n",
    "#             if elem['status'] == 'OK':\n",
    "#                 dist = elem['distance']['value']         # meters\n",
    "#                 tt   = elem['duration_in_traffic']['value']  # seconds\n",
    "#             else:\n",
    "#                 dist = float('inf')\n",
    "#                 tt   = float('inf')\n",
    "\n",
    "#             # store\n",
    "#             distance_matrix[i, j] = dist\n",
    "#             travel_time_matrix[i, j] = tt\n",
    "\n",
    "#             # update graph edge\n",
    "#             G.add_edge(i, j, distance=dist, time=tt)\n",
    "\n",
    "# fetch_matrix()\n",
    "\n",
    "# # travel_time_min = travel_time_matrix / 60.0\n",
    "# # travel_time_min = np.round(travel_time_min, 1)\n",
    "# # print(travel_time_min)\n",
    "\n",
    "# # Execute fetch\n",
    "# # epoch = datetime.now()\n",
    "# # print(f\"Matrix fetched at {epoch.isoformat()}\")\n",
    "# # np.save(\"distance_matrix.npy\", distance_matrix)\n",
    "\n",
    "# max_speed_matrix = np.full((num_locations, num_locations), 80.0)  # mostly 80 km/h\n",
    "# # override the known roads:\n",
    "# max_speed_matrix[3, 5] = max_speed_matrix[5, 3] = max_speed_matrix[5, 8] = max_speed_matrix[8, 5] = max_speed_matrix[8, 9] = max_speed_matrix[9, 8] = max_speed_matrix[9, 10] = max_speed_matrix[10, 9] = 100.0   # motorway\n",
    "# max_speed_matrix[5, 6] = max_speed_matrix[6, 5] = max_speed_matrix[6, 7] = max_speed_matrix[7, 6] = max_speed_matrix[7, 9] = max_speed_matrix[9, 7] = 30.0    # local street\n",
    "# max_speed_matrix[8, 6] = max_speed_matrix[6, 8] = 50.0 # local street\n",
    "# max_speed_matrix[0, 9] = max_speed_matrix[9, 0] = 60.0 # local street\n",
    "# max_speed_matrix[0, 10] = max_speed_matrix[10, 0] = 70.0 # local street\n",
    "\n",
    "# speed_matrix_list = []\n",
    "# travel_time_matrix_list = []\n",
    "# full_cost_list = []\n",
    "# for t in range(5):\n",
    "#     # 1) sample a random factor in [0.2, 1.0] for each edge\n",
    "#     rand_factor = np.random.uniform(0.5, 1.0, size=(num_locations, num_locations))\n",
    "    \n",
    "#     # 2) enforce symmetry so speed[i,j] == speed[j,i]:\n",
    "#     rand_factor = np.triu(rand_factor) + np.triu(rand_factor, 1).T\n",
    "    \n",
    "#     # 3) apply to the original matrix\n",
    "#     speed_matrix_list.append(max_speed_matrix * rand_factor)\n",
    "#     travel_time_matrix_list.append((distance_matrix / 1000) / (speed_matrix_list[t]))\n",
    "    \n",
    "#     full_cost_list.append(((distance_matrix / 1000) / (speed_matrix_list[t])) * C_T)\n",
    "\n",
    "\n",
    "# travel_time_min = travel_time_matrix_list[0] * 60.0\n",
    "# travel_time_min = np.round(travel_time_min, 1)\n",
    "# print(travel_time_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e776611",
   "metadata": {},
   "source": [
    "### Use saved Graph and Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef274c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / \"graph_G.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# Distance matrix for fully connected network    \n",
    "distance_matrixO = np.load(DATA_DIR / \"distance_matrix.npy\")\n",
    "# print(distance_matrix/1000)\n",
    "\n",
    "distance_matrix = distance_matrixO * 2   # scaling factor to make the problem more challenging (longer distances, more time, more differentiation between routes)\n",
    "\n",
    "# number of nodes\n",
    "num_locations = distance_matrix.shape[0]\n",
    "N = num_locations\n",
    "\n",
    "# 1) Read the CSV, using the 'Hours' column as the index\n",
    "dfO = pd.read_csv(DATA_DIR/MILP_filename, index_col=\"Hours\")\n",
    "# 2) Ensure index and column types are integers\n",
    "dfO.index = dfO.index.astype(int)\n",
    "dfO.index.name = \"Hour\"\n",
    "dfO.columns = dfO.columns.astype(int)\n",
    "# print(df.head())\n",
    "\n",
    "df = dfO  #* lb_factor\n",
    "\n",
    "# build a wrapped list of the 24 hours starting from start_hour\n",
    "####################################################################################################\n",
    "Pred_hours = [(start_hour + hh) % 24 for hh in range(len(df.index))]    # time-dependent\n",
    "# Pred_hours = [8] * len(df.index)                              # time-independent\n",
    "####################################################################################################\n",
    "\n",
    "# To build a connected network (not fully connected tho)\n",
    "# dynamic_edges[(i,j)] = RoadID\n",
    "dynamic_edges = {\n",
    "    (0,1): 165, (0,4):147, (0,7):164, (0,9):151, (0,10):116,\n",
    "    (1,2):128, (2,3):160, (2,4):131, (3,5):109, (4,5):147,\n",
    "    (5,8):154, (7,8):164, (8,9):117, (9,10):117,\n",
    "}\n",
    "\n",
    "# static_edges[(i,j)] = constant weight\n",
    "static_edges = {\n",
    "    (5,6): 30,\n",
    "    (6,7): 30,\n",
    "    (6,8): 50,\n",
    "    (7,9): 30,\n",
    "}\n",
    "\n",
    "# prepare container\n",
    "speed_matrix_list = []\n",
    "\n",
    "for h in Pred_hours:               # loops 0 through 23\n",
    "    M = np.full((N, N), 0, dtype=int)\n",
    "    Dis = np.full((N,N), np.inf)   # (distance will not change for each h)\n",
    "\n",
    "    speeds = df.loc[h]           # a Series indexed by RoadID (speed will chagne at each h)\n",
    "\n",
    "    # dynamic edges\n",
    "    for (i,j), Rid in dynamic_edges.items():\n",
    "        w = speeds[Rid]\n",
    "        M[i, j] = w  \n",
    "        M[j, i] = w\n",
    "        \n",
    "        Dis[i, j] = distance_matrix[i, j]     # bi-directional distances\n",
    "        Dis[j, i] = distance_matrix[j, i]\n",
    "\n",
    "    # static edges\n",
    "    for (i,j), w in static_edges.items():\n",
    "        M[i, j] = w\n",
    "        M[j, i] = w\n",
    "        \n",
    "        Dis[i, j] = distance_matrix[i, j]     # bi-directional distances\n",
    "        Dis[j, i] = distance_matrix[j, i]\n",
    "\n",
    "    speed_matrix_list.append(M)\n",
    "    \n",
    "    \n",
    "# Convert your distance to kilometers\n",
    "distance_km = Dis / 1000\n",
    "\n",
    "# Build your list of 24 travel-time matrices (in hours)\n",
    "travel_time_matrix_list = []\n",
    "for h, speed_mat in enumerate(speed_matrix_list):\n",
    "    # time (h) = distance (km) / speed (km/h)\n",
    "    safe_speed = np.where(speed_mat > 0, speed_mat, 1e-6)\n",
    "    tt = distance_km / safe_speed\n",
    "    np.fill_diagonal(tt, 0)\n",
    "    \n",
    "    travel_time_matrix_list.append(tt)\n",
    "    \n",
    "travel_time_min = travel_time_matrix_list[0] * 60.0\n",
    "travel_time_min = np.round(travel_time_min, 1)\n",
    "print(travel_time_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b00e5c",
   "metadata": {},
   "source": [
    "## Step 3. Dijkstra's Algorithm for Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd96e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intervals    = len(travel_time_matrix_list)   # considered time frames\n",
    "distance_cost = (Dis / 1000) * C_o   # Euros\n",
    "\n",
    "# prepare containers\n",
    "full_cost_list        = []    # list of cost matrices\n",
    "updated_cost_list      = []    # list of (N×N) cost matrices\n",
    "updated_distance_list     = []    # list of (N×N) base‐distance matrices\n",
    "updated_travel_time_list = []\n",
    "shortest_paths_list     = []    # list of dicts mapping (i,j)->path\n",
    "\n",
    "# for each interval (even tho the Distances are the same, for generic purpose/for different W)\n",
    "for t in range(num_intervals):\n",
    "    # --- 1) build full‐weight for this time t ---\n",
    "    tt_matrix = travel_time_matrix_list[0]  # in seconds\n",
    "    time_cost = tt_matrix * C_T    # Euros\n",
    "    W = distance_cost          # Euros\n",
    "    \n",
    "    full_cost_list.append(W)\n",
    "    \n",
    "    # --- 2) run bidir‐Dijkstra on W ---\n",
    "    updated_full_cost  = np.zeros((num_locations, num_locations))\n",
    "    updated_base_dist  = np.zeros((num_locations, num_locations))\n",
    "    updated_time_dist  = np.zeros((num_locations, num_locations))\n",
    "    spaths             = {}\n",
    "    \n",
    "    # local weight function that closes over W\n",
    "    def weight_cost(u, v, data):\n",
    "        return W[u, v]\n",
    "    \n",
    "    for i in range(num_locations):\n",
    "        for j in range(num_locations):\n",
    "            if i == j:\n",
    "                updated_full_cost[i, j] = 0.0\n",
    "                updated_base_dist[i, j] = 0.0\n",
    "                updated_time_dist[i, j] = 0.0\n",
    "                spaths[(i, j)]         = [i]\n",
    "            else:\n",
    "                cost, path = nx.bidirectional_dijkstra(G, i, j, weight=weight_cost)\n",
    "                updated_full_cost[i, j] = cost\n",
    "                # sum raw distances (meters) along path\n",
    "                total_d = sum(Dis[u, v] for u, v in zip(path[:-1], path[1:]))\n",
    "                total_time = sum(travel_time_matrix_list[t][u, v] for u, v in zip(path[:-1], path[1:]))\n",
    "                \n",
    "                updated_base_dist[i, j] = total_d\n",
    "                updated_time_dist[i, j] = total_time\n",
    "                spaths[(i, j)] = path\n",
    "    \n",
    "    # store for this t\n",
    "    updated_cost_list.append(updated_full_cost)\n",
    "    updated_distance_list.append(updated_base_dist)\n",
    "    updated_travel_time_list.append(updated_time_dist)\n",
    "    shortest_paths_list.append(spaths)\n",
    "    \n",
    "distance_matrix_ = updated_distance_list[0]\n",
    "travel_time_matrix_list = updated_travel_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5c4df",
   "metadata": {},
   "source": [
    "## Step 4. Formulate and Solve the Optimization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728048a8",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Define Cost Matrices and Other Parameters\n",
    "\n",
    "# Compute cost matrices.\n",
    "distance_cost = (distance_matrix / 1000) * C_o  # Euros\n",
    "time_cost_matrices = [tt * C_T for tt in travel_time_matrix_list]\n",
    "full_cost_matrices = time_cost_matrices  # Combined cost (in Euros)\n",
    "\n",
    "# Create dictionaries for model parameters.\n",
    "V_range = list(range(num_locations))       # Nodes 0,...,n (0 = depot)\n",
    "V_customers = list(range(1, num_locations))  # Customer nodes\n",
    "\n",
    "# Set of arcs (directed edges) for i != j.\n",
    "E = [(i, j) for i in V_range for j in V_range if i != j]\n",
    "\n",
    "# Convert matrices into dictionaries (keys: (i,j)).\n",
    "d_dict = {(i, j): distance_matrix[i, j]/1000 for (i, j) in E}\n",
    "t_dict = {(i, j, h): travel_time_matrix_list[h][i, j] for (i, j) in E for h in range(H)}   # for each (i,j) and h, store the travel time in hours\n",
    "cost_dict = {(i, j, h): full_cost_matrices[h][i, j]for (i, j) in E for h in range(H)}\n",
    "\n",
    "# Service time: 0 for depot, fixed service time for customers.\n",
    "s_dict = {i: (0 if i == 0 else service_time) for i in V_range}\n",
    "\n",
    "# Demand dictionary: only for customers.\n",
    "N_dict = {i: Cus_demand for i in V_customers}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e72a53",
   "metadata": {},
   "source": [
    "### Optimization Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60661de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Model(\"VRP_with_FullCost\")\n",
    "\n",
    "# Decision variables:\n",
    "# x[i,j] = 1 if arc (i,j) is used; 0 otherwise.\n",
    "x = mdl.binary_var_dict(E, name=\"x\")\n",
    "\n",
    "# z[i,j,h] = 1 if arc (i,j) is used and departure from i falls in interval h\n",
    "z = mdl.binary_var_dict(((i, j, h) for (i,j) in E for h in range(H)), name=\"z\")\n",
    "\n",
    "# l[i] = departure time from node i (hours after time=0)\n",
    "l = mdl.continuous_var_dict(V_range, lb=0, name=\"l\")\n",
    "\n",
    "# y[i,j] = number of packages carried along arc (i,j).\n",
    "y = mdl.continuous_var_dict(E, lb=0, name=\"y\")\n",
    "\n",
    "# T[i,j] = cumulative travel time upon arriving at j via arc (i,j).\n",
    "T = mdl.continuous_var_dict(E, lb=0, name=\"T\")\n",
    "\n",
    "# D[i,j] = cumulative travel distance upon arriving at j via arc (i,j).\n",
    "D_var = mdl.continuous_var_dict(E, lb=0, name=\"D\")\n",
    "\n",
    "# k = number of vehicles used.\n",
    "k = mdl.integer_var(lb=0, name=\"k\")\n",
    "\n",
    "# Objective: Minimize the total full cost over all used arcs.\n",
    "mdl.minimize(mdl.sum(cost_dict[i,j,h] * z[i,j,h] for (i,j) in E for h in range(H))+ (num_locations-1)*(service_time)*C_T + EV_cost * k)\n",
    "\n",
    "\n",
    "# --- Constraints ---\n",
    "\n",
    "# 1. Each customer must be visited exactly once. Vehicles must leave from and return to the depot.\n",
    "# C1\n",
    "for j in V_customers:\n",
    "    mdl.add_constraint(mdl.sum(x[i, j] for i in V_range if i != j) == 1, ctname=f\"visit_in_{j}\")\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(mdl.sum(x[i, j] for j in V_range if i != j) == 1, ctname=f\"visit_out_{i}\")\n",
    "# C2  \n",
    "mdl.add_constraint(mdl.sum(x[0, i] for i in V_customers) == k, ctname=\"depot_depart\")\n",
    "mdl.add_constraint(mdl.sum(x[i, 0] for i in V_customers) == k, ctname=\"depot_return\")\n",
    "\n",
    "# 2. Capacity constraints on package flow.\n",
    "# C3\n",
    "for (i, j) in E:\n",
    "    mdl.add_constraint(y[i, j] <= Truck_capacity * x[i, j], ctname=f\"capacity_{i}_{j}\")\n",
    "# Flow conservation for package delivery at each customer.\n",
    "# C4\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(\n",
    "        mdl.sum(y[j, i] for j in V_range if j != i) - mdl.sum(y[i, j] for j in V_range if j != i) == N_dict[i],\n",
    "        ctname=f\"demand_{i}\"\n",
    "    )\n",
    "    \n",
    "# 3. Time interval selection.\n",
    "# C5\n",
    "for (i, j) in E:\n",
    "    mdl.add_constraint(mdl.sum(z[i, j, h] for h in range(H)) == x[i, j], ctname=f\"pick_interval_{i}_{j}\")\n",
    "    \n",
    "# 4. Cumulative travel time constraints.\n",
    "# (a) Time flow balance for each nodes.\n",
    "for i in V_range:\n",
    "    for j in V_customers:\n",
    "        if i != j:\n",
    "            # only enforce when you actually use (i,j), if x[i,j]=1, then T[i,j] = d[i] + travel_ij\n",
    "            # C6\n",
    "            mdl.add_constraint(T[i,j] >= l[i] + mdl.sum(t_dict[i,j,h] * z[i,j,h] for h in range(H)) - M_big*(1 - x[i,j]),ctname=f\"Tdef_lo_{i}_{j}\")\n",
    "            # C7\n",
    "            mdl.add_constraint(T[i,j] <= l[i] + mdl.sum(t_dict[i,j,h] * z[i,j,h] for h in range(H)) + M_big*(1 - x[i,j]),ctname=f\"Tdef_hi_{i}_{j}\")  \n",
    "    \n",
    "# (b) Upper bound on travel time along paths arriving at a customer.\n",
    "# for i in V_range:\n",
    "#     for j in V_customers:\n",
    "#         if i != j:\n",
    "#             mdl.add_constraint(T[i, j] <= B_bar * x[i, j], ctname=f\"time_ub_{i}_{j}\")\n",
    "# C8\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(l[i] <= B_bar, ctname=f\"time_ub_{i}\")\n",
    "\n",
    "mdl.add_constraint(l[0] == 0, ctname=\"start_at_zero\")\n",
    "\n",
    "# (c) Flow of depurture time, leaving node i, l[i]\n",
    "# T[j,i] = arrival at i via (j,i) so departure d[i] must be T[j,i] + s_i on the one used arc\n",
    "for i in V_customers:\n",
    "    for j in V_range:\n",
    "        if i != j:\n",
    "            # if x[j,i]=1 then these two must coincide, otherwise the big‐M turns it off\n",
    "            # C9\n",
    "            mdl.add_constraint( l[i] >= T[j,i] + s_dict[i]   - M_big*(1 - x[j,i]), ctname=f\"dep_lb_{j}_{i}\")\n",
    "            # C10\n",
    "            mdl.add_constraint( l[i] <= T[j,i] + s_dict[i]   + M_big*(1 - x[j,i]), ctname=f\"dep_ub_{j}_{i}\")\n",
    "\n",
    "# (d) force z to match departure interval, h\n",
    "# C11\n",
    "for (i,j) in E:\n",
    "  for h in range(H):\n",
    "      mdl.add_constraint(l[i] >=  h*interval   - M_big*(1 - z[i,j,h]), ctname=f\"bin_lo_{i}_{j}_{h}\")\n",
    "      mdl.add_constraint(l[i] <= (h+1)*interval + M_big*(1 - z[i,j,h]), ctname=f\"bin_hi_{i}_{j}_{h}\")  \n",
    "    \n",
    "\n",
    "# 5. Cumulative travel distance constraints.\n",
    "# (a) Distance flow balance for each customer.\n",
    "# C12\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(\n",
    "        mdl.sum(D_var[i, j] for j in V_range if i != j) - mdl.sum(D_var[j, i] for j in V_range if j != i) ==\n",
    "        mdl.sum(d_dict[i, j] * x[i, j] for j in V_range if i != j),\n",
    "        ctname=f\"distance_flow_{i}\"\n",
    "    )\n",
    "# (b) Upper bound on cumulative distance along arcs arriving at a customer.\n",
    "# C13\n",
    "for i in V_range:\n",
    "    for j in V_customers:\n",
    "        if i != j:\n",
    "            mdl.add_constraint(D_var[i, j] <= (D_bar - d_dict[j, 0]) * x[i, j], ctname=f\"dist_ub_{i}_{j}\")\n",
    "# (c) Lower bound on cumulative distance for arcs leaving a customer.\n",
    "# C14\n",
    "for i in V_customers:\n",
    "    for j in V_range:\n",
    "        if i != j:\n",
    "            mdl.add_constraint(D_var[i, j] >= (d_dict[i, j] + d_dict[0, i]) * x[i, j], ctname=f\"dist_lb_{i}_{j}\")\n",
    "# (d) For arcs returning to the depot, ensure total distance does not exceed D_bar.\n",
    "# C15\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(D_var[i, 0] <= D_bar * x[i, 0], ctname=f\"return_dist_{i}\")\n",
    "# (e) For arcs departing the depot, set the distance equal to the distance from the depot.\n",
    "for i in V_customers:\n",
    "    mdl.add_constraint(D_var[0,i] == d_dict[0, i] * x[0, i], ctname=f\"departure_dist_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f880b6",
   "metadata": {},
   "source": [
    "### Solve the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = mdl.solve(log_output=True)\n",
    "\n",
    "if solution:\n",
    "    mdl.print_solution()\n",
    "else:\n",
    "    print(\"No solution found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206dc2a7",
   "metadata": {},
   "source": [
    "### Extract Optimal Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVs = k.solution_value\n",
    "\n",
    "# Assume depot is node 0 and V_range is the list of all nodes.\n",
    "routes = []\n",
    "depot = 0\n",
    "\n",
    "# Iterate over all arcs leaving the depot to start a route.\n",
    "for j in V_range:\n",
    "    if j == depot:\n",
    "        continue\n",
    "    # Check if the arc from depot to j is used.\n",
    "    if solution.get_value(x[depot, j]) > 0.5:\n",
    "        route = [depot, j]\n",
    "        current = j\n",
    "        # Continue following the route until we return to the depot.\n",
    "        while current != depot:\n",
    "            next_node = None\n",
    "            # Look for the arc leaving current with value 1.\n",
    "            for k in V_range:\n",
    "                if k != current and solution.get_value(x[current, k]) > 0.5:\n",
    "                    next_node = k\n",
    "                    break\n",
    "            # If no outgoing arc is found, break (shouldn't happen in a complete route).\n",
    "            if next_node is None:\n",
    "                break\n",
    "            route.append(next_node)\n",
    "            current = next_node\n",
    "        routes.append(route)\n",
    "\n",
    "# Print the routes.\n",
    "print(\"Routes:\")\n",
    "for r in routes:\n",
    "    print(\" -> \".join(map(str, r)))\n",
    "    \n",
    "if solution:\n",
    "    print(f\" → Optimal total cost: €{mdl.objective_value:.2f}\")\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"Runtime:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7babdb",
   "metadata": {},
   "source": [
    "## Step 5. Performance Evaluations\n",
    "Uses: routes (list of lists), Dis (meters), service_time (hours),\n",
    "start_hour (int), interval (hours), dynamic_edges, static_edges,\n",
    "V_range, V_customers, l (docplex vars), solution (solve result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce2e14",
   "metadata": {},
   "source": [
    "### 1) Extract MILP departure times l[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_MILP = {i: float(solution.get_value(l[i])) for i in V_range}\n",
    "\n",
    "# Load modified speeds and rebuild speed matrices for Pred_hours\n",
    "df_mod = pd.read_csv(DATA_DIR/True_filename, index_col=\"Hours\")\n",
    "df_mod.index = df_mod.index.astype(int)\n",
    "df_mod.index.name = \"Hour\"\n",
    "df_mod.columns = df_mod.columns.astype(int)\n",
    "\n",
    "Pred_hours_mod = [(start_hour + hh) % 24 for hh in range(len(df_mod.index))]\n",
    "num_intervals = len(Pred_hours_mod)\n",
    "# Convert your distance to kilometers\n",
    "N = Dis.shape[0]\n",
    "distance_km = Dis / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: get correct time-slice index from a departure time (hours since 0)\n",
    "def slice_idx_from_departure(dep_time_h: float) -> int:\n",
    "    # Which hour-of-day are we in? 0..23, aligned with Pred_hours start\n",
    "    # dep_time_h is measured from \"time 0\" (your start), so wrap around 24\n",
    "    hh = int(np.floor(dep_time_h / interval)) % num_intervals\n",
    "    return hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa965ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cost matrices\n",
    "distance_cost = (Dis / 1000) * C_o   # Euros\n",
    "\n",
    "# --- run bidir‐Dijkstra on W ---\n",
    "updated_full_cost  = np.zeros((num_locations, num_locations))\n",
    "updated_base_dist  = np.zeros((num_locations, num_locations))\n",
    "spaths_static = {}\n",
    "edges_static = {}\n",
    "\n",
    "# local weight function that closes over W\n",
    "def weight_cost(u, v, data):\n",
    "    return distance_cost[u, v]\n",
    "\n",
    "for i in range(num_locations):\n",
    "    for j in range(num_locations):\n",
    "        if i == j:\n",
    "            updated_full_cost[i, j] = 0.0\n",
    "            updated_base_dist[i, j] = 0.0\n",
    "            spaths_static[(i, j)]         = [i]\n",
    "        else:\n",
    "            cost, path = nx.bidirectional_dijkstra(G, i, j, weight=weight_cost)\n",
    "            updated_full_cost[i, j] = cost\n",
    "            spaths_static[(i, j)] = path\n",
    "            edges = list(zip(path[:-1], path[1:]))\n",
    "            edges_static[(i, j)] = edges\n",
    "            # sum raw distances (meters) along path\n",
    "            updated_base_dist[i, j] = sum(Dis[u, v] for u, v in edges)\n",
    "            \n",
    "distance_matrix_mod = updated_base_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b9a8d",
   "metadata": {},
   "source": [
    "### 2) MC loop to calculate outage probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diffs = []   # store Difference_h values per run\n",
    "all_true = []    # shape (MC, num_nodes)\n",
    "\n",
    "for mc in range(MC):\n",
    "    \n",
    "    # Create random multipliers between 0.8 and 1.2, same shape as df_mod\n",
    "    random_factors = np.random.normal(loc=MC_mean, scale=MC_std, size=df_mod.shape)     # np.random.uniform(MC_per_lb, MC_per_ub, size=df_mod.shape)\n",
    "    #random_factors = np.random.uniform(MC_per_lb, MC_per_ub)\n",
    "    df_randomized = df_mod * random_factors\n",
    "    df_randomized.head()    # Keep same structure (Hours × IDs)\n",
    "\n",
    "    speed_matrix_list_mod = []\n",
    "    for h in Pred_hours_mod:\n",
    "        M = np.zeros((N, N), dtype=float)\n",
    "        speeds = df_randomized.loc[h]  # Series of speeds (km/h) by RoadID\n",
    "\n",
    "        # dynamic edges\n",
    "        for (i, j), Rid in dynamic_edges.items():\n",
    "            w = float(speeds[Rid])\n",
    "            M[i, j] = w; M[j, i] = w\n",
    "\n",
    "        # static edges\n",
    "        for (i, j), w in static_edges.items():\n",
    "            w = float(w)\n",
    "            M[i, j] = w; M[j, i] = w\n",
    "\n",
    "        speed_matrix_list_mod.append(M)\n",
    "        \n",
    "    # Build travel-time matrices (hours) with modified speeds\n",
    "    travel_time_matrix_list_mod = []\n",
    "    for speed_mat in speed_matrix_list_mod:\n",
    "        safe_speed = np.where(speed_mat > 0, speed_mat, 1e-6)  # avoid divide-by-zero\n",
    "        tt = distance_km / safe_speed\n",
    "        np.fill_diagonal(tt, 0.0)\n",
    "        travel_time_matrix_list_mod.append(tt)\n",
    "\n",
    "    # reuse precomputed paths; recompute times only\n",
    "    updated_travel_time_list_mod = []\n",
    "    for t in range(num_intervals):\n",
    "        tt_mat = np.zeros((num_locations, num_locations))\n",
    "        for i in range(num_locations):\n",
    "            for j in range(num_locations):\n",
    "                if i == j:\n",
    "                    tt_mat[i, j] = 0.0\n",
    "                    continue\n",
    "                edges = edges_static[(i, j)]\n",
    "                tt_mat[i, j] = sum(travel_time_matrix_list_mod[t][u, v] for u, v in edges)\n",
    "        updated_travel_time_list_mod.append(tt_mat)\n",
    "        \n",
    "    #travel_time_matrix_list_mod = updated_travel_time_list_mod\n",
    "    \n",
    "    # Propagate along each route to compute new departure times l_new[i]\n",
    "    # Convention: l_new[0] = 0 (depot). Each customer node gets a single l_new (first time we visit it).\n",
    "    l_new = {i: None for i in V_range}\n",
    "    l_new[0] = 0.0\n",
    "\n",
    "    for route in routes:\n",
    "        # route like [0, i1, i2, ..., 0]\n",
    "        # start at depot\n",
    "        current_dep = 0.0\n",
    "        for idx in range(len(route) - 1):\n",
    "            i = route[idx]\n",
    "            j = route[idx + 1]\n",
    "\n",
    "            # pick TT matrix slice based on departure from i\n",
    "            h = slice_idx_from_departure(current_dep)\n",
    "            tt_ij = float(updated_travel_time_list_mod[h][i, j])\n",
    "\n",
    "            # arrive at j\n",
    "            arrival_j = current_dep + tt_ij\n",
    "\n",
    "            # set departure time at j (service except depot)\n",
    "            if j == 0:\n",
    "                # back to depot; no service time needed for next dep from depot in this route\n",
    "                next_dep_j = arrival_j\n",
    "            else:\n",
    "                # if first time we reach j, record its departure time\n",
    "                next_dep_j = arrival_j + service_time\n",
    "                if l_new[j] is None:\n",
    "                    l_new[j] = next_dep_j\n",
    "\n",
    "            # move on\n",
    "            current_dep = next_dep_j\n",
    "\n",
    "    # Fill any still-None (shouldn't happen, but just in case)\n",
    "    for i in V_range:\n",
    "        if l_new[i] is None:\n",
    "            l_new[i] = 0.0\n",
    "            \n",
    "    diffs = [l_new[i] - l_MILP[i] for i in V_range]\n",
    "    trues = [l_new[i] for i in V_range]\n",
    "    all_diffs.append(diffs)\n",
    "    all_true.append(trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df62694",
   "metadata": {},
   "source": [
    "### 3) Calculate outage probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_arr = np.asarray(all_true)   # shape (MC, num_nodes)\n",
    "\n",
    "# Map node IDs to column indices\n",
    "node_to_col = {node: k for k, node in enumerate(V_range)}\n",
    "cols = [node_to_col[n] for n in range(0, N) if n in node_to_col]\n",
    "\n",
    "# Check per run if any node in 0..10 exceeds B_bar\n",
    "any_exceed_per_run = (all_true_arr[:, cols] > B_bar).any(axis=1)\n",
    "\n",
    "# Outage probability\n",
    "outage_prob = any_exceed_per_run.mean()\n",
    "\n",
    "print(f\"Outage probability (any node 0–10 exceeds B_bar): {outage_prob:.4f}\")\n",
    "print(f\"Total runs with outage: {any_exceed_per_run.sum()} / {MC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9dcd2d",
   "metadata": {},
   "source": [
    "### Node Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15532073",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unit_in_seconds = 3600  # <-- change if needed\n",
    "\n",
    "# --- 1. Map nodes to columns and exclude node 0 ---\n",
    "\n",
    "node_to_col = {node: k for k, node in enumerate(V_range)}\n",
    "nodes_excl_0 = [node for node in V_range if node != 0]\n",
    "cols_excl_0  = [node_to_col[n] for n in nodes_excl_0]\n",
    "\n",
    "# True departure times for nodes != 0  → shape (MC, num_nodes-1)\n",
    "true_excl_0 = all_true_arr[:, cols_excl_0]\n",
    "\n",
    "# --- 2. Lateness for each node and each MC run (excluding node 0), in SECONDS ---\n",
    "\n",
    "lateness_base_units = np.maximum(0.0, true_excl_0 - B_bar)  # same unit as input\n",
    "lateness_sec = lateness_base_units * time_unit_in_seconds   # convert to seconds\n",
    "\n",
    "# --- 3. For each MC run: how many nodes on time vs delayed (excluding node 0) ---\n",
    "\n",
    "served_on_time_excl_0 = (true_excl_0 <= B_bar).sum(axis=1)   # shape (MC,)\n",
    "served_late_excl_0    = (true_excl_0 >  B_bar).sum(axis=1)   # shape (MC,)\n",
    "\n",
    "print(\"Average # of nodes on time per run (excluding node 0):\",\n",
    "      served_on_time_excl_0.mean())\n",
    "print(\"Average # of nodes late per run (excluding node 0):   \",\n",
    "      served_late_excl_0.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aae433",
   "metadata": {},
   "source": [
    "## Step 6. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9418081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase font sizes globally\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12\n",
    "})\n",
    "\n",
    "# --- 4+6. Combined figure: bar of #BSs late + lateness histogram (log counts) ---\n",
    "\n",
    "# Unique counts and how often they occur (for late BSs)\n",
    "unique_late, counts_late = np.unique(served_late_excl_0, return_counts=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left subplot: BSs served with delay\n",
    "axes[0].bar(unique_late, counts_late, width=0.8)\n",
    "axes[0].set_title(\"BSs served with delay\")\n",
    "axes[0].set_xlabel(\"No. of BSs late\")\n",
    "axes[0].set_ylabel(\"No. of simulation runs\")\n",
    "axes[0].set_xticks(unique_late)\n",
    "axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Right subplot: Overall lateness histogram (log-scale counts)\n",
    "axes[1].hist(lateness_sec.flatten(), bins=10, log=True)\n",
    "axes[1].set_xlabel(\"Lateness (seconds)\")\n",
    "axes[1].set_ylabel(\"Frequency (log scale)\")\n",
    "axes[1].set_title(\"Overall lateness distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc60bc",
   "metadata": {},
   "source": [
    "### Average lateness calculations (in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aba0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lateness_per_bs_sec = lateness_sec.mean(axis=0)  # shape: (n_BS,)\n",
    "\n",
    "print(\"Average lateness per BS (including zero-lateness runs), in seconds:\")\n",
    "for bs_id, avg_sec in zip(nodes_excl_0, avg_lateness_per_bs_sec):\n",
    "    print(f\"  BS {bs_id}: {avg_sec:.2f} s\")\n",
    "    \n",
    "# --- Average lateness per BS, ignoring on-time runs (only positive lateness) ---\n",
    "\n",
    "late_mask = lateness_sec > 0  # True where there is delay\n",
    "\n",
    "# Sum of lateness over late runs only\n",
    "sum_late_per_bs = (lateness_sec * late_mask).sum(axis=0)  # shape: (n_BS,)\n",
    "\n",
    "# Number of late runs per BS\n",
    "count_late_per_bs = late_mask.sum(axis=0)                 # shape: (n_BS,)\n",
    "\n",
    "# Avoid division by zero using np.divide with 'where'\n",
    "avg_lateness_pos_per_bs_sec = np.divide(\n",
    "    sum_late_per_bs,\n",
    "    count_late_per_bs,\n",
    "    out=np.zeros_like(sum_late_per_bs, dtype=float),\n",
    "    where=count_late_per_bs > 0\n",
    ")\n",
    "\n",
    "print(\"\\nAverage lateness per BS (ignoring on-time runs), in seconds:\")\n",
    "for bs_id, avg_sec, n_late in zip(nodes_excl_0, avg_lateness_pos_per_bs_sec, count_late_per_bs):\n",
    "    if n_late > 0:\n",
    "        print(f\"  BS {bs_id}: {avg_sec:.2f} s   (based on {n_late} late runs)\")\n",
    "    else:\n",
    "        print(f\"  BS {bs_id}: 0.00 s\")\n",
    "\n",
    "# Overall average lateness across all BSs and all runs (including zeros)\n",
    "overall_avg_lateness_sec = lateness_sec.mean()\n",
    "print(f\"\\nOverall average lateness (all BSs, all runs, including zeros): \"\n",
    "      f\"{overall_avg_lateness_sec:.2f} s\")\n",
    "\n",
    "#  Average positive lateness (only when there *is* a delay)\n",
    "positive_lateness = lateness_sec[lateness_sec > 0]\n",
    "\n",
    "if positive_lateness.size > 0:\n",
    "    overall_avg_positive_lateness_sec = positive_lateness.mean()\n",
    "    print(\"Average lateness *conditional on being late* (only > 0), in seconds:\",\n",
    "          f\"{overall_avg_positive_lateness_sec:.2f} s\")\n",
    "else:\n",
    "    print(\"No positive lateness observed: all BSs are always on time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87339d7",
   "metadata": {},
   "source": [
    "### Plot departure time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de109a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Boxplot of departure times for each BS across MC runs\n",
    "ax.boxplot(\n",
    "    [true_excl_0[:, j] for j in range(true_excl_0.shape[1])],\n",
    "    labels=nodes_excl_0,\n",
    "    showfliers=True\n",
    ")\n",
    "\n",
    "# Deadline line\n",
    "ax.axhline(B_bar, linestyle=\"--\", label=\"Deadline\")\n",
    "\n",
    "ax.set_xlabel(\"BS (node ID)\")\n",
    "ax.set_ylabel(\"Departure time (in hour)\")\n",
    "ax.set_title(\"Departure times for all BSs (excluding Depot)\")\n",
    "plt.xticks()\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68946a",
   "metadata": {},
   "source": [
    "### Plot Lateness distribution per node (excluding node 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c2e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.boxplot(\n",
    "    [lateness_sec[:, j] for j in range(lateness_sec.shape[1])],\n",
    "    labels=nodes_excl_0,\n",
    "    showfliers=True\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"BS ID\")\n",
    "ax.set_ylabel(\"Lateness (seconds)\")\n",
    "ax.set_title(\"Lateness distribution per BS (excluding Depot)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MILP vs. recomputed (modified speeds)\n",
    "rows = []\n",
    "for i in V_range:\n",
    "    rows.append({\n",
    "        \"Node\": i,\n",
    "        \"MILP_departure_h\": round(l_MILP[i], 3),     # hours with 4 decimals\n",
    "        \"True_departure_h\": round(l_new[i], 3),\n",
    "        \"Difference_h\": round(l_new[i] - l_MILP[i], 3),\n",
    "    })\n",
    "cmp_df = pd.DataFrame(rows).sort_values(\"Node\").reset_index(drop=True)\n",
    "\n",
    "# Pretty print & optionally save\n",
    "print(\"\\nDeparture time comparison (hours):\")\n",
    "print(cmp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f81e73",
   "metadata": {},
   "source": [
    "### Average differences across MC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d43f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diffs = np.array(all_diffs)  # shape (MC, num_nodes)\n",
    "all_true = np.array(all_true)    # (MC, num_nodes)\n",
    "\n",
    "avg_diffs = all_diffs.mean(axis=0)\n",
    "avg_true  = all_true.mean(axis=0)\n",
    "\n",
    "# Max values across MC runs\n",
    "max_diffs = all_diffs.max(axis=0)\n",
    "max_true  = all_true.max(axis=0)\n",
    "\n",
    "# Build DataFrame\n",
    "cmp_mc_df = pd.DataFrame({\n",
    "    \"Node\": V_range,\n",
    "    \"MILP_departure_h\": [round(l_MILP[i], 3) for i in V_range],\n",
    "    \"Avg_True_departure_h\": np.round(avg_true, 3),\n",
    "    \"Avg_Difference_h\": np.round(avg_diffs, 3),\n",
    "    \"Max_True_departure_h\": np.round(max_true, 3),\n",
    "    \"Max_Difference_h\": np.round(max_diffs, 3)\n",
    "})\n",
    "\n",
    "print(\"\\nAverage results across MC runs:\")\n",
    "print(cmp_mc_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4c132",
   "metadata": {},
   "source": [
    "### Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check exact equality\n",
    "equal_exact = np.array_equal(distance_matrix_, distance_matrix_mod)\n",
    "\n",
    "# check numerical closeness (safer for floats)\n",
    "equal_close = np.allclose(distance_matrix_, distance_matrix_mod, rtol=1e-9, atol=1e-12)\n",
    "\n",
    "print(\"Exact equal:\", equal_exact)\n",
    "print(\"Numerically close:\", equal_close)\n",
    "\n",
    "# if not close, print maximum difference\n",
    "if not equal_close:\n",
    "    diff = np.abs(distance_matrix_ - distance_matrix_mod)\n",
    "    print(\"Max difference:\", diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "df_m = pd.read_csv(DATA_DIR/MILP_filename)\n",
    "df_t = pd.read_csv(DATA_DIR/True_filename)\n",
    "\n",
    "try:\n",
    "    assert_frame_equal(df_m.sort_index(axis=1).reset_index(drop=True),\n",
    "                       df_t.sort_index(axis=1).reset_index(drop=True),\n",
    "                       check_dtype=False, check_like=True)\n",
    "    print(\"Inputs identical\")\n",
    "except AssertionError as e:\n",
    "    print(\"Input mismatch:\", e)\n",
    "\n",
    "# Show where they diverge\n",
    "cols = set(df_m.columns).intersection(df_t.columns)\n",
    "for c in sorted(cols):\n",
    "    ne = (df_m[c].reset_index(drop=True) != df_t[c].reset_index(drop=True))\n",
    "    if getattr(df_m[c], \"dtype\", None) == float:\n",
    "        ne = (df_m[c].reset_index(drop=True).round(6) !=\n",
    "              df_t[c].reset_index(drop=True).round(6))\n",
    "    if ne.any():\n",
    "        i = ne.idxmax()\n",
    "        print(f\"First diff in {c} at row {i}: {df_m[c].iloc[i]} vs {df_t[c].iloc[i]}\")\n",
    "        break\n",
    "    \n",
    "# Example guards to neutralize alignment and rounding differences\n",
    "X = df_m.to_numpy(copy=True)    # no index alignment\n",
    "# compute Lb_departure_h_raw = ...\n",
    "# compute True_departure_h_raw = ...\n",
    "MILP_departure_h = pd.Series(cmp_df.MILP_departure_h).round(6).mod(24)\n",
    "True_departure_h = pd.Series(cmp_df.True_departure_h).round(6).mod(24)\n",
    "\n",
    "print(\"Same length:\", len(MILP_departure_h) == len(True_departure_h))\n",
    "print(\"Max abs diff:\", (MILP_departure_h - True_departure_h).abs().max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
